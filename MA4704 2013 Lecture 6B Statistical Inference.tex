
\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx}  % Font Family
\usepackage{helvet}   % Font Family
\usepackage{color}

\mode<presentation> {
 \usetheme{Default} % was Frankfurt
 \useinnertheme{rounded}
 \useoutertheme{infolines}
 \usefonttheme{serif}
 %\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}

\setbeamercovered{dynamic}

\title[MA4704]{Technology Mathematics 4 \\ {\normalsize Lecture 6B}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize kevin.obrien@ul.ie}}
\date{Spring 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}

\renewcommand{\arraystretch}{1.5}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Todays' Class}

\begin{itemize}
\item At the start of Lecture 6B, we will continue covering the tutorial questions and past paper questions.
\item We will also start a new section \textbf{\textit{Statistical Inference}} by discussing some important definitions and concepts.
\end{itemize}
\end{frame}
%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference}

\begin{itemize}
\item Statistics and Population parameters
\item Random Sampling
\item Properties of Estimators
\item Estimation (Point and Interval)
\item Confidence Intervals
\item The Central Limit Theorem
\item Standard Errors
\end{itemize}


\end{frame}


%----------------------------------------------------%


\begin{frame}
\frametitle{Statistical Inference : Definitions}
\begin{itemize}
\item A \textbf{\emph{population}} consists of an entire set of objects, observations, or scores that have something in common.
For example, a population might be defined as students in a university.

\item Some populations are only hypothetical. Consider an experiment where a die is thrown 100 times and the sum of the scores was recorded.
\item The researcher might define a population as the sums that would result if this experiment was repeated an infinite number of times.
\item The population is hypothetical in the sense that it is not reasonable to repeat this experiment indefinitely.
\item The distribution of a population can be described by several parameters such as the mean and standard deviation.

\end{itemize}
\end{frame}
%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Sample}
\begin{itemize}

\item A sample is a subset of a population.
\item Suppose we are interested in some characteristic of a population ( e.g. amount of time spent on the internet)
\item Since it is usually impractical to test every member of a population, a sample from the population is typically
the best approach available.
\item To be properly representative of a population, a sample should be both \textbf{\emph{ random}} and sufficiently large.


\end{itemize}
\end{frame}



%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Random Sampling}
\begin{itemize}

\item In random sampling, each item or element of the population has an equal chance of being chosen at each draw.
\item A sample is random if the method for obtaining the sample meets the criterion of randomness
(each element having an equal chance at each draw).


\end{itemize}
\end{frame}


%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Biased Sampling}
\begin{itemize}


\item A biased sample is one in which the method used to create the sample results
in samples that are systematically different from the population.


\item For instance, consider a market research project on attitudes of attendees towards an event they attended.

\item Collecting the data by publishing a questionnaire and asking people to fill it out and
send it in would produce a biased sample.

\item People interested enough to spend their time and energy filling out and sending in the questionnaire
are likely to have different attitudes about the event than those not taking the time to fill out the questionnaire.

\end{itemize}
\end{frame}



%----------------------------------------------------%


\begin{frame}
\frametitle{Statistical Inference : Parameters}
\begin{itemize}
\item A parameter is a numerical quantity measuring some aspect of a population of scores.
\item The population mean $\mu$ and population variance $\sigma^2$ are commonly used parameters.
\item Another commonly used parameter is the population proportion $\pi$.
\item (Remark : greek letters are used to designate parameters.)
\item Parameters are rarely known and are usually estimated by \textbf{\emph{statistics}} computed from samples.
\end{itemize}
\end{frame}


%----------------------------------------------------%


\begin{frame}
\frametitle{Statistical Inference : Statistics}
\begin{itemize}
\item The most common use of the word `statistics'is for describing a wide range of techniques and procedures for analyzing, interpreting and displaying data.
\item In a second usage, a ``statistic" is defined as a numerical quantity (such as the sample mean) calculated from a sample.
\item Sample mean $\bar{x}$ and sample standard deviation $s$ are types of statistics.
\item These statistics are used to estimate population parameters.
\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Estimators}
\begin{itemize}
\item Three important attributes of statistics as estimators are: \begin{itemize} \large
\item unbiasedness, \item consistency,  \item  relative efficiency.\end{itemize}
\item A statistic is unbiased if, in the long run, it's value is reasonably close to the parameter it is estimating.
\item An estimator is consistent if the estimator tends to get closer to the parameter it is estimating as the sample size increases.
\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Estimators}
\begin{itemize}

\item The efficiency of a statistic is the degree to which the statistic is stable from sample to sample.
\item That is, the less subject to sampling fluctuation a statistic is, the more efficient it is.
\item \textbf{\emph{Sampling fluctuation}} refers to the extent to which a statistic takes on different values with different samples.
\item That is, it refers to how much the statistic's value fluctuates from sample to sample.

\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Inferential Statistics}
\begin{itemize}
\item Inferential statistics are used to draw inferences about a population from a sample.
\item Consider an experiment in which 10 subjects who performed a task after 24 hours of sleep
deprivation scored 12 points lower than 10 subjects who performed after a normal night's sleep.
\item Is the difference real or could it be due to chance?
\item How much larger could the real difference be than the 12 points found in the sample?
\item These are the types of questions answered by inferential statistics.
\end{itemize}
\end{frame}


%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Estimation}
\begin{itemize}
\item When a parameter is being estimated, the estimate can be either a single number or it can be a range of numbers.
\item When the estimate is a single number, such as a sample mean, the estimate is called a \textbf{\emph{point estimate}}.
\item When the estimate is a range of values, the estimate is called an \textbf{\emph{interval estimate}}.
\item \textbf{\emph{Confidence intervals}} are used for interval estimation.
\item As we will soon see, point estimates are not usually as informative as confidence intervals.
\end{itemize}
\end{frame}


%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Confidence Intervals}
\begin{itemize}
\item Confidence intervals allow us to use sample data to estimate a parameter value, such as a population mean.
\item A confidence interval is a range of values for which we can be confident (at a specific level) that parameter value (such as the population mean)  lies within.
\item A confidence level will have a specified level of confidence, commonly $95\%$.
\item The $95\%$ confidence interval is a range of values which contains the parameter value of interest with a probability of 0.95.
\item We can expected that a $95\%$ confidence interval will not contain the parameter value of interest with a probability of 0.05.
\end{itemize}
\end{frame}


%----------------------------------------------------%
\begin{frame}
\frametitle{Statistical Inference : Confidence Intervals}
\begin{itemize}

\item It is natural to interpret a $95\%$ confidence interval on the mean as an interval with a 0.95 probability of containing the population mean.
\item However, the proper interpretation is not that simple.
\item Consider the case in which 1,000 studies estimating the value of $\mu$  in a certain population all resulted
in estimates between 30 and 40.
\item Suppose one more study was conducted and the $95\%$ confidence interval on $\mu$ was computed
to be $40 \leq \mu \leq 50$ (based on that one study).

\item The probability that $\mu$ is between 40 and 50 is very low, the confidence interval not withstanding.

\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Central Limit Theorem}

\begin{itemize}

\item Before we can begin computing confidence intervals, we must introduce the \textbf{\emph{Central Limit Theorem}}.

\item Suppose random sample of size $n$ are drawn from any distribution, with the distribution having a mean of $\mu$ (equivalently $E(X)$) and variance of $\sigma^2$ (i.e. standard deviation of $\sigma$).

\item Also suppose that the sample size is large ( i.e. $n > 30$ ).

\item The sample means tend to form a normal distribution with mean $\mu$ and standard deviation $ { \sigma \over \sqrt{n} }$

\item We call the standard deviation of the sample means the \textbf{\emph{standard error}}
\item Standard error is commonly denoted as $S.E.$
\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Central Limit Theorem}

\begin{itemize}

\item Recall from earlier lectures, an experiment was carried out where the sum of 100 throws of a die were recorded.

\item The underlying distribution of the die values is not normally distributed. \\(Actually discrete uniform between 1 and 6.)

\item Nonetheless the distribution of the sum of 100 throws was normally distributed. Necessarily the distribution of the average score for 100 throws is normally distributed.

\end{itemize}
\end{frame}

\frame{
\frametitle{Distribution of means}

\begin{center}
\includegraphics[scale=0.4]{6BHist}
\end{center}

}
%----------------------------------------------------%
\begin{frame}
\frametitle{Exercise}
From previous lecture, we know the following properties of the dice distribution. \\(Remark: In this case we know the variance, but that is not always the case.)
\begin{itemize}
\item Mean (Expected Value) $E(X) = \mu = 3.5$
\item Variance $V(X) = \sigma^2 = 2.9166$
\item Standard deviation $= \sigma = 1.707$
\end{itemize}

Compute the standard error $S.E.(\bar{x})$ for the mean value $\bar{x}$ of die values:
\begin{itemize}
\item when the die is thrown 25 times
\item when the die is thrown 225 times.
\end{itemize}
\end{frame}

%----------------------------------------------------%
\begin{frame}
\frametitle{Exercise}
\begin{itemize}
\item When the die is thrown 25 times n = 25
\item Therefore the standard error is
\[ {\sigma \over \sqrt{n}}  = {1.707 \over \sqrt{25}} = {1.707 \over 5} = 0.3415. \]
\item When the die is thrown 225 times: n = 225
\item Therefore the standard error is
\[ {\sigma \over \sqrt{n}}  = {1.707 \over \sqrt{225}} = {1.707 \over 15} = 0.1138. \]

\end{itemize}
\end{frame}
\frame{
\frametitle{Distribution of means}

\begin{center}
\includegraphics[scale=0.4]{6BHist2}
\end{center}

}

\frame{
\frametitle{Distribution of means}

\begin{center}
\includegraphics[scale=0.4]{6BHist3}
\end{center}

}

%----------------------------------------------------%
\begin{frame}
\frametitle{Exercise}
\begin{itemize}
\item Compare the two histograms on the previous slides. These horizontal range of value is the same for both histograms.

\item We can see that with a larger sample size ($n=225$), the distribution of sample means are clustered closely around the 3.5 mark, and have much less dispersion than distribution of sample means with a sample size $n=25$.

\end{itemize}
\end{frame}
\end{document}


