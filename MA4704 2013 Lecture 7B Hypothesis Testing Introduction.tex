\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx}  % Font Family
\usepackage{helvet}   % Font Family
\usepackage{color}

\mode<presentation> {
 \usetheme{Default} % was Frankfurt
 \useinnertheme{rounded}
 \useoutertheme{infolines}
 \usefonttheme{serif}
 %\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}

\setbeamercovered{dynamic}

\title[MA4704]{Technological Mathematics 4 \\ {\normalsize MA4704 Lecture 7B/7C}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize Kevin.obrien@ul.ie}}
\date{Spring Semester 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}
\renewcommand{\arraystretch}{1.5}


%------------------------------------------------------------------------%
\begin{document}
%----------------------------------------------------------------------------------------------------%
\begin{frame}
\titlepage
\end{frame}
%--------------------------%
% - Interpreting Confidence Interval. READY
% - Introducing Hypothesis testing. READY
% - The Null and Alternative Hypotheses.
% - Computing Test Statistics.
% - P-values
% - Critical values
% - Decision Rules
% - One Side ad Two Sided tests
% - Type I and Type 2 Error
% - The Paired T test.
%----------------------------------------------------------------------------------------------------%




%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Hypothesis Testing : Revision from Last Class}
\large
\begin{itemize} \item
A hypothesis test is a method of making decisions using experimental data. \item A result is called \textbf{\emph{statistically significant}} if it is unlikely to have occurred by chance.


%\item A statistical test procedure is comparable to a trial where a defendant is considered innocent as long as his guilt is not proven.\item  The prosecutor tries to prove the guilt of the defendant. Only when there is enough charging evidence the defendant is condemned.
%\end{itemize}

%\end{frame}


%--------------------------------------------------------------------------------------------------------------------------%
%\begin{frame}
%\frametitle{Hypothesis tests (Null and Alternative Hypotheses) }
%\large
%The phrase "test of significance" was coined by Ronald Fisher;
%"Critical tests of this kind may be called tests of significance, and when such tests are available we may discover whether a second sample is or is not significantly different from the first." \\
%\begin{itemize}
\item The null hypothesis (which we will denoted $H_0$) is an hypothesis about a population parameter, such as the population mean $\mu$. \item The purpose of hypothesis testing is to test the viability of the null hypothesis in the light of experimental data. \item The alternative hypothesis $H_1$ expresses the exact opposite of the null hypothesis. \item Depending on the data, the null hypothesis either will or will not be \textbf{rejected} as a viable possibility in favour of the alternative hypothesis.
\end{itemize}

\end{frame}







%----------------------------------------------------------------------------------------------------%
\frame{
\frametitle{Writing the Null Hypothesis}
%In statistics, a hypothesis is a claim or statement made around a property of a population.
%A hypothesis test (also called a test of significance) is a standard procedure for testing a claim about that %property.
\begin{itemize}
%\item The null hypothesis is denoted $H_0$.
\item It will often express it's argument in the form of a mathematical relation, with a written description of the hypothesis (we will do it this way).
\item $H_0$ will always refer to the population parameter ( i.e. never the observed value) and must contain a condition of equality. (i.e. ` = ' , `$ \leq$' or `$\geq$')
\end{itemize}
}


%----------------------------------------------------------------------------------------------------%
\frame{
\frametitle{Number of Tails}
Inference Procedures are either \textbf{One-tailed} or \textbf{Two-Tailed}.


 Confidence Intervals are always two-tailed . Hypothesis tests can either be one-tailed or two-tailed. It is important to know how determine correctly the number of tails.
\begin{itemize}
\item The alternative hypothesis indicates the number of tails.
\item A rule of thumb is to consider how many alternative to the $H_0$ is offered by $H_1$.
\item When $H_1$ includes either of these relational operators;`$>$' ,`$<$' , only one alternative is offered.
\item When $H_1$ includes the $\neq$ relational operators, two alternatives are offered (i.e.`$>$' or `$<$').
\end{itemize}
}


%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Significance Level ($\alpha$)}

\begin{itemize}
\item In hypothesis testing, the significance level $\alpha$ is the criterion used for rejecting the null hypothesis. \item The significance level is used in hypothesis testing as follows: First, the difference between the result (i.e. observed statistic or point estimate)  of the experiment and the \textbf{null value} \item The null value is the expected value of this statistic, assuming that the null hypothesis is true), is determined.(i.e.we denote this  \textbf{\textit{Observed - Null}}). \item Then, assuming the null hypothesis is true, the probability of a difference that large or larger is computed . \item Finally, this probability is compared to the significance level.\item  If the probability is less than or equal to the significance level, then the null hypothesis is rejected and the outcome is said to be statistically significant.
\end{itemize}
\end{frame}

%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Hypothesis Testing}
The inferential step to conclude that the null hypothesis is false goes as follows: The data (or data more extreme) are very unlikely given that the null hypothesis is true.
\bigskip
This means that:
\begin{itemize}
\item[(1)] a very unlikely event occurred or
\item[(2)] the null hypothesis is false.
\end{itemize}
\bigskip
The inference usually made is that the null hypothesis is false. Importantly it doesn't prove the null hypothesis to be false.
\end{frame}
%--------------------------------------------------------------------------------------------------------------------------%


\begin{frame}
\frametitle{Significance (Die Throw Example)}
\begin{itemize}
\item Suppose that the outcome of the die throw experiment was a sum of 401. In previous lectures, a simulation study found that only in approximately $1.75\%$ of cases would a fair die yield this result.
\item However, in the case of a crooked die (i.e. one that favours high numbers) this result would not be unusual.
\item A reasonable interpretation of this experiment is that the die is crooked, but importantly the experiment doesn't prove it one way or the other.
\item We will discuss the costs of making a wrong decision later (Type I and Type II errors).
\end{itemize}
\end{frame}
%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Significance Level}

\begin{itemize}
\item Traditionally, experimenters have used either the 0.05 level (sometimes called the 5\% level) or the 0.01 level (1\% level), although the choice of levels is largely subjective.  \item The lower the significance level, the more the data must diverge from the null hypothesis to be significant. \item Therefore, the 0.01 level is more conservative than the 0.05 level. \item The Greek letter alpha ($\alpha$) is sometimes used to indicate the significance level. \item We will $\alpha =0.05$ in this module. (i.e. 5\%) \end{itemize}
\end{frame}

%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Hypothesis Testing and p-values}
\begin{itemize}
\item In hypothesis tests, the difference between the observed value and the parameter value specified by $H_0$ is computed and the probability of obtaining a difference this large or large is calculated.
\item The probability of obtaining data as extreme, or more extreme, than the expected value under the null hypothesis is called the \textbf{\emph{p-value}}.
\item There is often confusion about the precise meaning of the p-value probability computed in a significance test. It is not the probability of the null hypothesis itself.
\item Thus, if the probability value is $0.0175$, this does not mean that the probability that the null hypothesis is either true or false is $0.0175$.
\item It means that the probability of obtaining data as different or more different from the null hypothesis as those obtained in the experiment is $0.0175$.
\end{itemize}
\end{frame}

%---------------------------------------------------------------------------------------------%

\frame{
\frametitle{Significance Level}

\begin{itemize}
\item The significance level of a statistical hypothesis test is a fixed probability of wrongly rejecting the null hypothesis $H_0$, if it is in fact true.

\item Equivalently, the significance level (denoted by $\alpha$) is the probability that the test statistics will fall into the \textbf{\emph{critical region}}, when the null hypothesis is actually true. ( We will discuss the critical region shortly).

\item Common choices for $\alpha$ are $0.05$ and $0.01$
\end{itemize}
}

%--------------------------%

\begin{frame}
\frametitle{The Hypothesis Testing Procedure }
We will use both of the following four step procedures for hypothesis testing. The level of significance must be determined in advance.

\textbf{Procedure 1}\\
The first procedures is as follows:

\begin{itemize}
\item Formally write out the null and alternative hypotheses (already described).
\item Compute the \emph{\textbf{test statistic}} - a standardized value of the numerical outcome of an experiment.
\item Compute the p-value for that test statistic.
\item Make a decision based on the p-value. (smaller than $\alpha$ or $\alpha/2$? - reject null)
\end{itemize}
(We will re-visit this approach later in the course).
\end{frame}

%--------------------------%

\begin{frame}
\frametitle{The Hypothesis Testing Procedure }
The second procedures is very similar to the first, but is more practicable for written exams, so we will use this one also. The first two steps are the same.
\textbf{Procedure 2}\\
\begin{itemize}
\item Formally write out the null and alternative hypotheses (already described).
\item Compute the test statistic
\item Determine the \emph{\textbf{critical value}} (described shortly)
\item Make a decision based on the critical value. (We call this step the \textbf{decision rule} step, and shall discuss it in depth shortly).
\end{itemize}
(We will mostly use this approach to hypothesis testing).
\end{frame}
\begin{frame}

%------------------------------------------------%

\frametitle{Test Statistics}
\begin{itemize}
\item A test statistic is a quantity calculated from our sample of data. Its value is used to decide whether or not the null hypothesis should be rejected in our hypothesis test.
\item The choice of a test statistic will depend on the assumed probability model and the hypotheses under question.
    \item The general structure of a test statistic is
\[ \mbox{TS}  = {\mbox{Observed Value} - \mbox{Null Value}  \over \mbox{Std. Error}}\]
\item Recall: The ``Null Value" is the expected value, assuming that the null hypothesis is true.
\end{itemize}
\end{frame}
%----------------------------------------------%

\begin{frame}
\frametitle{The Test Statistic}
\begin{itemize}

\item In our dice experiment, we observed a value of 401. Under the null hypothesis, the expected value was 350.
\item The standard error is of the same form as for confidence intervals. $s \over \sqrt{n}$.
\item (For this experiment the standard error is 17.07).
\item The test statistic is therefore \[ \mbox{TS}  = {401 - 350  \over 17.07} = 2.99 \]
\end{itemize}
\end{frame}

%--------------------------%

\begin{frame}
\frametitle{The Critical Value}


\begin{itemize}
\item The critical value(s) for a hypothesis test is a threshold to which the value of the test statistic in sample is compared to determine whether or not the null hypothesis is rejected.
\item The critical value for any hypothesis test depends on the significance level at which the test is carried out, and whether the test is one-sided or two-sided.
\item The critical value is determined the exact same way as quantiles for confidence intervals; using Murdoch Barnes table 7.


\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Critical Region}
In class : graphical representation of material on the black-board is scheduled here.



\textbf{Important:}
A critical value is any value that separates the critical region ( where we reject the null hypothesis) for thatvalues of the test statistic that do not lead to a rejection of the null hypothesis.
\end{frame}
%--------------------------%


\begin{frame}
\frametitle{One Tailed Hypothesis test}
\begin{itemize}
\item A one-sided test is a statistical hypothesis test in which the values for which we can reject the null hypothesis, $H_0$ are located entirely in one tail of the probability distribution (either the upper tail, or the lower tail, but not both).

\item In other words, the critical region for a one-sided test is the set of values beyond than the critical value for the test

\item A one-sided test is also referred to as a one-tailed test of significance.

\item A rule of thumb is to consider the alternative hypothesis.  If only one alternative is offered by $H_1$ (i.e. a $`<'$ or a $`>'$ is present, then it is a one tailed test.)
\item (When computing quantiles from Murdoch Barnes table 7, we set $k=1$)
\end{itemize}
\end{frame}


%---------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Two Tailed Hypothesis test}
\begin{itemize}
\item
A two-sided test is a statistical hypothesis test in which the values for which we can reject the null hypothesis, $H_0$ are located in both tails of the probability distribution, on an equal basis.

\item A two-sided test is also referred to as a two-tailed test of significance.
\item A rule of thumb is to consider the alternative hypothesis.  If only one alternative is offered by $H_1$ (i.e. a $`\neq'$ is present, then it is a two tailed test.)
\item (When computing quantiles from Murdoch Barnes table 7, we set $k=2$)

\end{itemize}
\end{frame}


%--------------------------%


\begin{frame}
\frametitle{Determining the Critical value}
\begin{itemize} \item The critical value for a hypothesis test is a threshold to which the value of the test statistic in a sample is compared to determine whether or not the null hypothesis is rejected.

\item The critical value for any hypothesis test depends on the significance level at which the test is carried out, and whether the test is one-sided or two-sided.
\end{itemize}
\end{frame}


%--------------------------%


\begin{frame}
\frametitle{Determining the Critical value}
\begin{itemize}
\item A pre-determined level of significance $\alpha$ must be specified. Usually it is set at 5\% (0.05).
\item The number of tails must be known. ( $k$ is either 1 or 2).
\item Sample size will be also be an issue. We must decide whether to use $n-1$ degrees of freedom or $\infty$ degrees of freedom, depending on the sample size in question.
\item The manner by which we compute critical value is identical to the way we compute quantiles.We will consider this in more detail during tutorials.
\item For the time being we will use 1.96 as a critical value.
\end{itemize}
\end{frame}

%------------------------------------------%

\begin{frame}
\frametitle{Decision Rule:  The Critical Region}
\begin{itemize}
\item The critical region CR (or rejection region RR) is a set of values of the test statistic for which the null hypothesis is rejected in a hypothesis test. \item That is, the sample space for the test statistic is partitioned into two regions; one region (the critical region) will lead us to reject the null hypothesis $H_0$, the other will not.

\item A test statistic is in the critical region if the absolute value of the test statistic is greater than the critical value.
    \item So, if the observed value of the test statistic is a member of the critical region, we conclude ``Reject $H_0$"; if it is not a member of the critical region then we conclude "Do not reject $H_0$".
\item (Demonstration on BlackBoard).
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Critical Region }

Remark: the absolute value fuction of some value x is denoted $|x|$. It is the magnitude of the value without consideration of whether the value is positive or negative.


\begin{itemize}
\item Let TS denote Test Statistic and CV denoted Critical Value.
\item $|TS| > CV$ Then we reject null hypothesis.
\item $|TS| \leq CV$ Then we \textbf{fail to reject} null hypothesis.

\item For our die-throw example; TS = 2.99, CV = 1.96.
\item Here $|2.99| > 1.96$ we reject the null hypothesis that the die is fair.
\item Consider this in the context of ``proof". (More on this in next class)
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Performing a Hypothesis test}
\textbf{Important}
To summarize: a hypothesis test can be considered as a four step process
\begin{itemize}
\item[1] Formally writing out the null and alternative hypothesis.
\item[2] Computing the test statistic.
\item[3] Determining the critical value.
\item[4] Using the decision rule.
\end{itemize}
\end{frame}

%----------------------------------------------------------------------------------------------------%

\frame{
\frametitle{Conclusions in Hypothesis Testing}
\textbf{Important}
\begin{itemize}
\item We always test the null hypothesis.
\item We either \textbf{\emph{reject}} the null hypothesis, or
\item We \textbf{\emph{ fail to reject}} the null hypothesis.
\item our conclusion is always one of these two.
\end{itemize}
}


%--------------------------%
\frame{
\frametitle{p-values}
(Mentioned Previously, but discussed again)
\begin{itemize}
\item The p-value (or P-value or probability value) is the probability of getting a value of the test statistic that is at least as extreme as the one representing the sample data, assuming the null hypothesis is true.
\item The null hypothesis is rejected if the p-value is very small, such as less than 0.05.
\item When performing an inference procedure on a computer, it is much more common to use the p-value as a basis for decision, rather than the critical value
\end{itemize}
}



%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{p-values}
\begin{itemize}
\item The less likely the obtained results (or more extreme results) under the null hypothesis, the more confident one should be that the null hypothesis is false.The null hypothesis should not be rejected once and for all. The possibility that it was falsely rejected is always present, and, all else being equal, the lower the p-value, the lower this possibility.
\item According to this view, research reports should not contain the p-value, only whether or not the values were significant (at or below the significance level).
\item
However it is much more reasonable to just report the p-values. That way each reader can make up his or her mind about just how convinced they are that the null hypothesis is false.
\end{itemize}
\end{frame}

\end{document}












%----------------------------------------------------------------------------------------------------%
\frame{
\begin{itemize}
\item $\mu_d$ mean value for the population of differences.
\item $\bar{d}$ mean value for the sample of differences,
\item $s_d$ standard deviation of the differences for the paired sample data.
\item $n$ number of pairs
\end{itemize}


}




%---------------------------------------------------------------------------------------------%
\frame{
\frametitle{The Critical region}
The critical region ( or rejection region ) is the set of all values of the test statistic that causes us to rejec the null hypothesis.

}
\frame{

Test statistics for testing a claim about a mean, when the population variance is known.

\[ Z = {\bar{x}  - \mu \over {\sigma \over \sqrt{n}}} \]
}





%--------------------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{P-values}
\large
\begin{itemize}
\item The null hypothesis either is or is not rejected at the previously stated significance level. Thus, if an experimenter originally stated that he or she was using the $\alpha = 0.05$ significance level and p-value was subsequently calculated to be $0.042$, then the person would reject the null hypothesis at the 0.05 level. \item If p-value had been 0.0001 instead of 0.042 then the null hypothesis would still be rejected at the 0.05 significance level.  \item
The experimenter would not have any basis to be more confident that the null hypothesis was false with a p-value of 0.0001 than with a p-value of 0.041. \item Similarly, if the p had been 0.051 then the experimenter would fail to reject the null hypothesis
\end{itemize}

\end{frame}

%------------------------------------------------------------------------%
\frame{
\frametitle{Paired T test}
\large
\begin{itemize}
\item Firstly we have to compute each of the case-wise differences.
\item Then we have to compute the mean value of these differences.
\item Lastly we also have to compute the standard deviation of the differences.
\end{itemize}
}
%----------------------------------------------------------------------%
\frame{
To test the null hypothesis that the true mean difference is zero, the procedure is as
follows:
1. Calculate the difference $(di = y_i − x_i)$ between the two observations on each pair,
making sure you distinguish between positive and negative differences.
2. Calculate the mean difference, $\bar{d}$.


3. Calculate the standard deviation of the differences, $s_d$, and use this to calculate the
standard error of the mean difference, $SE(\bar{d}) = {s_d \over \sqrt{n}}$

4. Calculate the t-statistic, which is given by $ T ={ \bar{d} \over SE(\bar{d})}$.

Under the null hypothesis, this statistic follows a t-distribution with $n − 1$ degrees of freedom.

}
%------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Formulae}
\begin{itemize}
\item The schedule of formulae that will be at the back of your examination paper will be posted on the SULIS site shortly.
\item It is advisable to familiarise yourself with the contents before the examination.
\item Please let me know as soon as possible if there are any issues with it.
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------------------------------------%



%-------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{The Paired t-test}
\begin{itemize}
\item We will often be required to compute the case-wise differences, the average of those differences and the standard deviation of those difference.

\item The mean difference for a set of differences between paired observations is
\[ \bar{d} = \sum d_i \over n \]

\item The computational formula for the standard deviation of the differences
between paired observations is
\[s_d = \sqrt{ {\sum d_i^2 - n\bar{d}^2 \over n-1}}\]
\item It is nearly always a small sample test.
\end{itemize}
\end{frame}


%----------------------------------------------------------------------------------------------------%
\frame{
\frametitle{Paired T test}
\begin{itemize}
\item $\mu_d$ mean value for the population of differences.
\item The null hypothesis is that that $\mu_d = 0$
\item Given $\bar{d}$ mean value for the sample of differences, and $s_d$ standard deviation of the differences for the paired sample data, we can compute this test in the same manner as a one-sample test for the mean
\end{itemize}
}





\end{document}












